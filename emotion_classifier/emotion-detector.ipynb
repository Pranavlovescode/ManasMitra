{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fffca5e-d3cd-4e7d-b75c-15738b2da803",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03100b16-b416-496a-8261-790b88093d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\prana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5c40f6-1448-455f-99c4-9dae4d6d51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b69e5-1e55-4886-b91d-7dcfb88be627",
   "metadata": {},
   "source": [
    "### Checking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e9c742-7f03-46a9-83ed-da7f4b63b450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 16 06:36:52 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 577.03                 Driver Version: 577.03         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   53C    P8              3W /   70W |       0MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           17996    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c332dcc-63f1-4ef7-8388-fce6cf359a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0438834-0e7d-46e7-b9bb-2960b229ef9e",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad85ea5-904e-4fd3-860d-6aace6a0332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
    "\n",
    "texts = dataset[\"train\"][\"text\"]\n",
    "labels = dataset[\"train\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2bfea3-1467-44ee-914e-b545d9ac2574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1200001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "glove_path='./dolma_300_2024_1.2M.100_combined.txt'\n",
    "# Load embeddings into a dictionary\n",
    "glove_model = {}\n",
    "with open(glove_path, 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_model[word] = vector\n",
    "\n",
    "print(f\"Loaded {len(glove_model)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934ba23-027d-479d-82f3-7e78d49b997e",
   "metadata": {},
   "source": [
    "### Label preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8debb3-562c-4ab1-8a68-cd269a1eaf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 28\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(labels)\n",
    "num_classes = len(mlb.classes_)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7c29a-9021-42e4-aa74-b3064dbf05e5",
   "metadata": {},
   "source": [
    "### Tokenization + Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f6cd3f-4384-47f1-9930-37794795ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [word_tokenize(t.lower()) for t in texts]\n",
    "\n",
    "# Build vocabulary\n",
    "all_words = [word for sent in tokenized for word in sent]\n",
    "word_freq = Counter(all_words)\n",
    "vocab = {w: i + 2 for i, (w, _) in enumerate(word_freq.most_common(20000))}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1\n",
    "\n",
    "def encode_text(tokens, max_len=40):\n",
    "    ids = [vocab.get(t, 1) for t in tokens[:max_len]]\n",
    "    ids += [0] * (max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "encoded_texts = [encode_text(t) for t in tokenized]\n",
    "X = torch.tensor(encoded_texts)\n",
    "Y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29097f61-2227-4b4d-8509-49df2106bdad",
   "metadata": {},
   "source": [
    "### Dataset + Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0b3b54-8e3a-47a5-afc2-e454058674df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(EmotionDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(EmotionDataset(X_val, y_val), batch_size=64)\n",
    "\n",
    "\n",
    "embedding_dim = 300\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Initialize embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Fill matrix with GloVe vectors\n",
    "for word, idx in vocab.items():\n",
    "    if word in glove_model:\n",
    "        embedding_matrix[idx] = glove_model[word]\n",
    "    else:\n",
    "        # If word not in GloVe, leave it as zeros (or random)\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16ea62f4-d356-4c9e-80d5-b12cb567c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd4e76e-3fe3-4eed-b763-b5a8b27386cc",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e37fb80-6a4b-4691-bdb0-78b3a5c053ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEmotionClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, embedding_matrix):\n",
    "        super().__init__()\n",
    "        # Load pretrained embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32), \n",
    "            freeze=False  # set True to freeze embeddings\n",
    "        )\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(emb)\n",
    "        # Concatenate final states from both directions\n",
    "        out = self.fc(torch.cat((h_n[-2], h_n[-1]), dim=1))\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6fbe1-4ebf-4a7c-a0ef-b1593bf0693f",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4ac277-b6b1-4743-baa7-034233eee83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "embedding_dim = 300  # must match glove embeddings\n",
    "hidden_dim = 256\n",
    "\n",
    "model = LSTMEmotionClassifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    embedding_matrix=embedding_matrix\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def multi_label_accuracy(y_pred, y_true):\n",
    "    preds = (y_pred > 0.5).float()\n",
    "    correct = (preds == y_true).float().sum()\n",
    "    total = y_true.numel()\n",
    "    return (correct / total).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d12b1c-6be8-4e2b-bf91-fa142dabfb40",
   "metadata": {},
   "source": [
    "### Training Loop with epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "921b4404-ce5c-43c7-86b1-1612d1af0cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]\n",
      "Train Loss: 0.1384, Train Acc: 95.94%\n",
      "Val Loss:   0.1155, Val Acc:   96.49%\n",
      "------------------------------------------------------------\n",
      "Epoch [2/15]\n",
      "Train Loss: 0.1054, Train Acc: 96.61%\n",
      "Val Loss:   0.0999, Val Acc:   96.68%\n",
      "------------------------------------------------------------\n",
      "Epoch [2/15]\n",
      "Train Loss: 0.1054, Train Acc: 96.61%\n",
      "Val Loss:   0.0999, Val Acc:   96.68%\n",
      "------------------------------------------------------------\n",
      "Epoch [3/15]\n",
      "Train Loss: 0.0919, Train Acc: 96.87%\n",
      "Val Loss:   0.0972, Val Acc:   96.67%\n",
      "------------------------------------------------------------\n",
      "Epoch [3/15]\n",
      "Train Loss: 0.0919, Train Acc: 96.87%\n",
      "Val Loss:   0.0972, Val Acc:   96.67%\n",
      "------------------------------------------------------------\n",
      "Epoch [4/15]\n",
      "Train Loss: 0.0823, Train Acc: 97.13%\n",
      "Val Loss:   0.0962, Val Acc:   96.70%\n",
      "------------------------------------------------------------\n",
      "Epoch [4/15]\n",
      "Train Loss: 0.0823, Train Acc: 97.13%\n",
      "Val Loss:   0.0962, Val Acc:   96.70%\n",
      "------------------------------------------------------------\n",
      "Epoch [5/15]\n",
      "Train Loss: 0.0734, Train Acc: 97.41%\n",
      "Val Loss:   0.0996, Val Acc:   96.65%\n",
      "------------------------------------------------------------\n",
      "Epoch [5/15]\n",
      "Train Loss: 0.0734, Train Acc: 97.41%\n",
      "Val Loss:   0.0996, Val Acc:   96.65%\n",
      "------------------------------------------------------------\n",
      "Epoch [6/15]\n",
      "Train Loss: 0.0653, Train Acc: 97.68%\n",
      "Val Loss:   0.1042, Val Acc:   96.56%\n",
      "------------------------------------------------------------\n",
      "Epoch [6/15]\n",
      "Train Loss: 0.0653, Train Acc: 97.68%\n",
      "Val Loss:   0.1042, Val Acc:   96.56%\n",
      "------------------------------------------------------------\n",
      "Epoch [7/15]\n",
      "Train Loss: 0.0581, Train Acc: 97.94%\n",
      "Val Loss:   0.1109, Val Acc:   96.51%\n",
      "------------------------------------------------------------\n",
      "Epoch [7/15]\n",
      "Train Loss: 0.0581, Train Acc: 97.94%\n",
      "Val Loss:   0.1109, Val Acc:   96.51%\n",
      "------------------------------------------------------------\n",
      "Epoch [8/15]\n",
      "Train Loss: 0.0515, Train Acc: 98.17%\n",
      "Val Loss:   0.1179, Val Acc:   96.43%\n",
      "------------------------------------------------------------\n",
      "Epoch [8/15]\n",
      "Train Loss: 0.0515, Train Acc: 98.17%\n",
      "Val Loss:   0.1179, Val Acc:   96.43%\n",
      "------------------------------------------------------------\n",
      "Epoch [9/15]\n",
      "Train Loss: 0.0457, Train Acc: 98.41%\n",
      "Val Loss:   0.1272, Val Acc:   96.35%\n",
      "------------------------------------------------------------\n",
      "Epoch [9/15]\n",
      "Train Loss: 0.0457, Train Acc: 98.41%\n",
      "Val Loss:   0.1272, Val Acc:   96.35%\n",
      "------------------------------------------------------------\n",
      "Epoch [10/15]\n",
      "Train Loss: 0.0402, Train Acc: 98.60%\n",
      "Val Loss:   0.1347, Val Acc:   96.24%\n",
      "------------------------------------------------------------\n",
      "Epoch [10/15]\n",
      "Train Loss: 0.0402, Train Acc: 98.60%\n",
      "Val Loss:   0.1347, Val Acc:   96.24%\n",
      "------------------------------------------------------------\n",
      "Epoch [11/15]\n",
      "Train Loss: 0.0354, Train Acc: 98.78%\n",
      "Val Loss:   0.1453, Val Acc:   96.08%\n",
      "------------------------------------------------------------\n",
      "Epoch [11/15]\n",
      "Train Loss: 0.0354, Train Acc: 98.78%\n",
      "Val Loss:   0.1453, Val Acc:   96.08%\n",
      "------------------------------------------------------------\n",
      "Epoch [12/15]\n",
      "Train Loss: 0.0310, Train Acc: 98.94%\n",
      "Val Loss:   0.1546, Val Acc:   96.10%\n",
      "------------------------------------------------------------\n",
      "Epoch [12/15]\n",
      "Train Loss: 0.0310, Train Acc: 98.94%\n",
      "Val Loss:   0.1546, Val Acc:   96.10%\n",
      "------------------------------------------------------------\n",
      "Epoch [13/15]\n",
      "Train Loss: 0.0272, Train Acc: 99.08%\n",
      "Val Loss:   0.1629, Val Acc:   96.03%\n",
      "------------------------------------------------------------\n",
      "Epoch [13/15]\n",
      "Train Loss: 0.0272, Train Acc: 99.08%\n",
      "Val Loss:   0.1629, Val Acc:   96.03%\n",
      "------------------------------------------------------------\n",
      "Epoch [14/15]\n",
      "Train Loss: 0.0237, Train Acc: 99.19%\n",
      "Val Loss:   0.1690, Val Acc:   96.00%\n",
      "------------------------------------------------------------\n",
      "Epoch [14/15]\n",
      "Train Loss: 0.0237, Train Acc: 99.19%\n",
      "Val Loss:   0.1690, Val Acc:   96.00%\n",
      "------------------------------------------------------------\n",
      "Epoch [15/15]\n",
      "Train Loss: 0.0205, Train Acc: 99.31%\n",
      "Val Loss:   0.1819, Val Acc:   95.94%\n",
      "------------------------------------------------------------\n",
      "Epoch [15/15]\n",
      "Train Loss: 0.0205, Train Acc: 99.31%\n",
      "Val Loss:   0.1819, Val Acc:   95.94%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += multi_label_accuracy(outputs, y_batch)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_train_acc = total_acc / len(train_loader)\n",
    "\n",
    "    # ===========================\n",
    "    # Validation\n",
    "    # ===========================\n",
    "    model.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += multi_label_accuracy(outputs, y_batch)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_acc = val_acc / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc*100:.2f}%\")\n",
    "    print(f\"Val Loss:   {avg_val_loss:.4f}, Val Acc:   {avg_val_acc*100:.2f}%\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c90aeda1-967d-4e49-a292-7ba2c5ff76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "\n",
    "# def predict_emotions(text, tokenizer, model, device, label_names):\n",
    "#     # Tokenize single text\n",
    "#     encoding = tokenizer(\n",
    "#         text,\n",
    "#         return_tensors='pt',\n",
    "#         truncation=True,\n",
    "#         padding='max_length',\n",
    "#         max_length=128\n",
    "#     )\n",
    "\n",
    "#     # Move to GPU/CPU\n",
    "#     input_ids = encoding['input_ids'].to(device)\n",
    "#     attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "#     # Run through model\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids, attention_mask)\n",
    "#         probs = sigmoid(outputs).cpu().numpy()[0]\n",
    "\n",
    "#     # Convert probabilities to label names (threshold = 0.5)\n",
    "#     threshold = 0.5\n",
    "#     predicted_labels = [label_names[i] for i, p in enumerate(probs) if p >= threshold]\n",
    "#     return predicted_labels, probs\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "# üîπ Function to encode and predict emotions for a single text\n",
    "def predict_emotion_lstm(text, model, vocab, device, label_names):\n",
    "    # Tokenize + numericalize\n",
    "    tokens = [vocab.get(word.lower(), vocab['<UNK>']) for word in text.split()]\n",
    "    # Pad/truncate\n",
    "    max_len = 50\n",
    "    if len(tokens) < max_len:\n",
    "        tokens += [vocab['<PAD>']] * (max_len - len(tokens))\n",
    "    else:\n",
    "        tokens = tokens[:max_len]\n",
    "\n",
    "    # Convert to tensor\n",
    "    x = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        probs = model(x).cpu().numpy()[0]\n",
    "\n",
    "    # Apply threshold\n",
    "    threshold = 0.5\n",
    "    predicted_labels = [label_names[i] for i, p in enumerate(probs) if p >= threshold]\n",
    "\n",
    "    return predicted_labels, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c60811-44d6-416f-9463-29f3f669f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\",\n",
    "    \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\",\n",
    "    \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\",\n",
    "    \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\",\n",
    "    \"surprise\", \"neutral\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5334d1f1-78cd-4c17-9edc-3eec038578d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: I am so happy and grateful for your help!\n",
      "Predicted Emotions: ['gratitude', 'joy']\n",
      "\n",
      "Text: This is the worst movie I‚Äôve ever seen.\n",
      "Predicted Emotions: ['disgust']\n",
      "\n",
      "Text: I can‚Äôt believe I actually won the competition!\n",
      "Predicted Emotions: ['approval']\n",
      "\n",
      "Text: I feel nervous about my job interview tomorrow.\n",
      "Predicted Emotions: ['nervousness']\n",
      "\n",
      "Text: Wow, that performance was absolutely amazing!\n",
      "Predicted Emotions: ['neutral']\n",
      "\n",
      "Text: I‚Äôm really disappointed with your behavior.\n",
      "Predicted Emotions: ['disappointment']\n",
      "\n",
      "Text: I miss you so much it hurts.\n",
      "Predicted Emotions: ['sadness']\n",
      "\n",
      "Text: What a confusing tutorial... I don‚Äôt get it.\n",
      "Predicted Emotions: ['confusion']\n",
      "\n",
      "Text: I‚Äôm proud of what I‚Äôve achieved today.\n",
      "Predicted Emotions: ['pride']\n",
      "\n",
      "Text: Nothing special happened today, just a normal day.\n",
      "Predicted Emotions: ['neutral']\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    \"I am so happy and grateful for your help!\",\n",
    "    \"This is the worst movie I‚Äôve ever seen.\",\n",
    "    \"I can‚Äôt believe I actually won the competition!\",\n",
    "    \"I feel nervous about my job interview tomorrow.\",\n",
    "    \"Wow, that performance was absolutely amazing!\",\n",
    "    \"I‚Äôm really disappointed with your behavior.\",\n",
    "    \"I miss you so much it hurts.\",\n",
    "    \"What a confusing tutorial... I don‚Äôt get it.\",\n",
    "    \"I‚Äôm proud of what I‚Äôve achieved today.\",\n",
    "    \"Nothing special happened today, just a normal day.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    labels, probs = predict_emotion_lstm(text, model, vocab, device, label_names)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Predicted Emotions: {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8efb540",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m os.makedirs(\u001b[33m'\u001b[39m\u001b[33mmodel_files\u001b[39m\u001b[33m'\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Save the model state dictionary\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m torch.save(\u001b[43mmodel\u001b[49m.state_dict(), \u001b[33m'\u001b[39m\u001b[33memotion_model.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel saved to emotion_model.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Save the vocabulary\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model, vocabulary and other necessary components\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Create a directory for model files if it doesn't exist\n",
    "os.makedirs('model_files', exist_ok=True)\n",
    "\n",
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), 'emotion_model.pth')\n",
    "print(\"Model saved to emotion_model.pth\")\n",
    "\n",
    "# Save the vocabulary\n",
    "with open('vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
    "print(\"Vocabulary saved to vocab.txt\")\n",
    "\n",
    "# Create a helper module in emotion_model.py for easy import\n",
    "with open('emotion_model.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\"\"import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Define the model architecture\n",
    "class LSTMEmotionClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        # Initialize embedding layer\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                torch.tensor(embedding_matrix, dtype=torch.float32), \n",
    "                freeze=False\n",
    "            )\n",
    "        else:\n",
    "            # If no pretrained embeddings, initialize randomly\n",
    "            self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "            \n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(emb)\n",
    "        # Concatenate final states from both directions\n",
    "        out = self.fc(torch.cat((h_n[-2], h_n[-1]), dim=1))\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# List of emotion labels\n",
    "emotion_labels = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\",\n",
    "    \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\",\n",
    "    \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\",\n",
    "    \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\",\n",
    "    \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "# Function to load the vocabulary\n",
    "def load_vocab(vocab_file='vocab.txt'):\n",
    "    try:\n",
    "        with open(vocab_file, 'r', encoding='utf-8') as f:\n",
    "            vocab = json.load(f)\n",
    "        return vocab\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading vocabulary: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path='emotion_model.pth', vocab_file='vocab.txt'):\n",
    "    try:\n",
    "        # Load vocabulary\n",
    "        vocab = load_vocab(vocab_file)\n",
    "        if vocab is None:\n",
    "            return None, None\n",
    "            \n",
    "        # Determine device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Initialize model\n",
    "        embedding_dim = 300\n",
    "        hidden_dim = 256\n",
    "        num_classes = len(emotion_labels)\n",
    "        \n",
    "        model = LSTMEmotionClassifier(\n",
    "            vocab_size=len(vocab),\n",
    "            embed_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "        \n",
    "        # Load model weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        return model, vocab, device\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, None, torch.device(\"cpu\")\n",
    "\n",
    "# Function to predict emotions from text\n",
    "def predict_emotion(text, model=None, vocab=None, device=None):\n",
    "    if model is None or vocab is None:\n",
    "        model, vocab, device = load_model()\n",
    "        \n",
    "    if model is None or vocab is None:\n",
    "        return [{\"label\": \"neutral\", \"score\": 1.0}]\n",
    "    \n",
    "    # Tokenize and encode text\n",
    "    tokens = [vocab.get(word.lower(), vocab['<UNK>']) for word in text.split()]\n",
    "    \n",
    "    # Pad/truncate\n",
    "    max_len = 50\n",
    "    if len(tokens) < max_len:\n",
    "        tokens += [vocab['<PAD>']] * (max_len - len(tokens))\n",
    "    else:\n",
    "        tokens = tokens[:max_len]\n",
    "\n",
    "    # Convert to tensor and predict\n",
    "    try:\n",
    "        x = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            probs = model(x).cpu().numpy()[0]\n",
    "        \n",
    "        # Format results in the style expected by integrated_cbt\n",
    "        results = []\n",
    "        threshold = 0.5\n",
    "        for i, label in enumerate(emotion_labels):\n",
    "            if probs[i] >= threshold:\n",
    "                results.append({\"label\": label, \"score\": float(probs[i])})\n",
    "        \n",
    "        # If no emotions above threshold, return neutral\n",
    "        if not results:\n",
    "            results.append({\"label\": \"neutral\", \"score\": 1.0})\n",
    "            \n",
    "        # Sort by score (descending)\n",
    "        results = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return [{\"label\": \"neutral\", \"score\": 1.0}]\n",
    "\"\"\")\n",
    "\n",
    "print(\"Created emotion_model.py with all necessary functions for integration\")\n",
    "\n",
    "# Test the emotion_model.py module we just created\n",
    "print(\"\\nTesting the emotion_model module...\")\n",
    "import importlib\n",
    "import emotion_model\n",
    "importlib.reload(emotion_model)  # Force reload in case it was imported before\n",
    "\n",
    "# Test loading the model\n",
    "try:\n",
    "    model_reload, vocab_reload, device_reload = emotion_model.load_model('emotion_model.pth', 'vocab.txt')\n",
    "    print(\"‚úÖ Successfully loaded model from file\")\n",
    "    \n",
    "    # Test a prediction\n",
    "    test_text = \"I am feeling really happy today!\"\n",
    "    results = emotion_model.predict_emotion(test_text, model_reload, vocab_reload, device_reload)\n",
    "    print(f\"\\nTest text: {test_text}\")\n",
    "    print(\"Detected emotions:\")\n",
    "    for emotion in results:\n",
    "        print(f\"  - {emotion['label']}: {emotion['score']:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing the module: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a551d47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully with model_state_dict format\n",
      "Vocabulary saved to vocab.txt\n",
      "\n",
      "You can also run save_model.py to format the model correctly for integration\n",
      "This script will ensure the model is saved in the right format for integrated_cbt_streamlit.py\n"
     ]
    }
   ],
   "source": [
    "# Save the model in a format compatible with integrated_cbt_streamlit.py\n",
    "import torch\n",
    "\n",
    "# Save model in the format expected by integrated_cbt_streamlit.py\n",
    "model_data = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"vocab_size\": len(vocab)\n",
    "}\n",
    "torch.save(model_data, \"emotion_model.pth\")\n",
    "print(\"Model saved successfully with model_state_dict format\")\n",
    "\n",
    "# Save vocabulary as JSON if not already done\n",
    "import json\n",
    "with open(\"vocab.txt\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
    "print(\"Vocabulary saved to vocab.txt\")\n",
    "\n",
    "# You can now use the save_model.py script if needed to re-save the model\n",
    "print(\"\\nYou can also run save_model.py to format the model correctly for integration\")\n",
    "print(\"This script will ensure the model is saved in the right format for integrated_cbt_streamlit.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
